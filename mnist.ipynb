{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zaRBBnDwJ9la",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2g17LprJ8kZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3c836f2-fee7-4401-d9e7-16966c9b60c3"
      },
      "cell_type": "code",
      "source": [
        "old_v = tf.logging.get_verbosity()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\",one_hot=True)\n",
        "tf.logging.set_verbosity(old_v)\n"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O4ydYYgvPdHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nodes1 = 500\n",
        "nodes2 = 500\n",
        "nodes3 = 500\n",
        "\n",
        "\n",
        "classes = 10\n",
        "batch_size = 100\n",
        "\n",
        "x = tf.placeholder('float',[None,784])\n",
        "y = tf.placeholder('float')\n",
        "\n",
        "def neural_network_model(data):\n",
        "  layer1 = {'weights':tf.Variable(tf.random_normal([784,nodes1])),\n",
        "            'biases':tf.Variable(tf.random_normal([nodes1]))}\n",
        "  layer2 = {'weights':tf.Variable(tf.random_normal([nodes1,nodes2])),\n",
        "            'biases':tf.Variable(tf.random_normal([nodes2]))}\n",
        "  layer3 = {'weights':tf.Variable(tf.random_normal([nodes2,nodes3])),\n",
        "             'biases':tf.Variable(tf.random_normal([nodes3]))}\n",
        "  layer_out = {'weights':tf.Variable(tf.random_normal([nodes3,classes])),\n",
        "            'biases':tf.Variable(tf.random_normal([classes]))}\n",
        "  \n",
        "  l1 = tf.add(tf.matmul(data,layer1['weights']),layer1['biases'])\n",
        "  l1 = tf.nn.relu(l1)\n",
        "  \n",
        "  l2 = tf.add(tf.matmul(l1,layer2['weights']),layer2['biases'])\n",
        "  l2 = tf.nn.relu(l2)\n",
        "\n",
        "  l3 = tf.add(tf.matmul(l2,layer3['weights']),layer3['biases'])\n",
        "  l3 = tf.nn.relu(l3)\n",
        "  \n",
        "  l_out = tf.add(tf.matmul(l3,layer_out['weights']),layer_out['biases'])\n",
        "  \n",
        "  return l_out\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qmrnrr5LU5e7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_neural_network():\n",
        "  prediction = neural_network_model(x)\n",
        "  cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = prediction,labels = y))\n",
        "  optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
        "  \n",
        "  n_epochs = 100\n",
        "  \n",
        "  with tf.Session() as sess:\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "      epoch_loss =  0\n",
        "      for _ in range(int(mnist.train.num_examples/batch_size)):\n",
        "        train_data,train_labels = mnist.train.next_batch(batch_size)\n",
        "        _, c  =  sess.run([optimizer,cost],  feed_dict = {x:train_data,y:train_labels})\n",
        "        epoch_loss += c\n",
        "      print('Epoch : ',epoch,'/',n_epochs,' loss : ',epoch_loss)\n",
        "      \n",
        "      \n",
        "      \n",
        "    correct = tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct,'float'))\n",
        "    print('Accuracy : ',accuracy.eval({x:mnist.test.images,y: mnist.test.labels}))\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PGDmli5XWlb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        },
        "outputId": "f096639b-99e9-40a4-f08f-5597771a4d45"
      },
      "cell_type": "code",
      "source": [
        "train_neural_network()\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :  0 / 100  loss :  1783988.7825622559\n",
            "Epoch :  1 / 100  loss :  395791.8266906738\n",
            "Epoch :  2 / 100  loss :  213471.24092197418\n",
            "Epoch :  3 / 100  loss :  122430.53272074461\n",
            "Epoch :  4 / 100  loss :  77312.19033966959\n",
            "Epoch :  5 / 100  loss :  49003.83624732494\n",
            "Epoch :  6 / 100  loss :  32047.24737302959\n",
            "Epoch :  7 / 100  loss :  23262.02036897838\n",
            "Epoch :  8 / 100  loss :  18421.741354377395\n",
            "Epoch :  9 / 100  loss :  17946.54710168818\n",
            "Epoch :  10 / 100  loss :  14426.04351978004\n",
            "Epoch :  11 / 100  loss :  15681.57687667607\n",
            "Epoch :  12 / 100  loss :  13666.02034540847\n",
            "Epoch :  13 / 100  loss :  12055.056046076119\n",
            "Epoch :  14 / 100  loss :  13523.956017792225\n",
            "Epoch :  15 / 100  loss :  8299.216875374317\n",
            "Epoch :  16 / 100  loss :  11918.977353283026\n",
            "Epoch :  17 / 100  loss :  11795.969401677847\n",
            "Epoch :  18 / 100  loss :  9722.174022640884\n",
            "Epoch :  19 / 100  loss :  12402.610765611287\n",
            "Epoch :  20 / 100  loss :  8755.044108331194\n",
            "Epoch :  21 / 100  loss :  7214.9264414310455\n",
            "Epoch :  22 / 100  loss :  6895.022036219958\n",
            "Epoch :  23 / 100  loss :  8975.574072089043\n",
            "Epoch :  24 / 100  loss :  6881.94504673779\n",
            "Epoch :  25 / 100  loss :  8282.591663306801\n",
            "Epoch :  26 / 100  loss :  6412.807355001569\n",
            "Epoch :  27 / 100  loss :  4718.401292622089\n",
            "Epoch :  28 / 100  loss :  7617.755664014286\n",
            "Epoch :  29 / 100  loss :  7580.4979079377645\n",
            "Epoch :  30 / 100  loss :  6232.154964052141\n",
            "Epoch :  31 / 100  loss :  4942.824844747782\n",
            "Epoch :  32 / 100  loss :  3912.3156957924366\n",
            "Epoch :  33 / 100  loss :  6338.934793670178\n",
            "Epoch :  34 / 100  loss :  5223.586080816087\n",
            "Epoch :  35 / 100  loss :  5910.779438093305\n",
            "Epoch :  36 / 100  loss :  4924.376489368383\n",
            "Epoch :  37 / 100  loss :  5581.769327789778\n",
            "Epoch :  38 / 100  loss :  4953.41722185224\n",
            "Epoch :  39 / 100  loss :  4841.2998446404235\n",
            "Epoch :  40 / 100  loss :  3786.53840703073\n",
            "Epoch :  41 / 100  loss :  5763.632265720367\n",
            "Epoch :  42 / 100  loss :  3956.6334424316883\n",
            "Epoch :  43 / 100  loss :  3822.6149479508344\n",
            "Epoch :  44 / 100  loss :  4891.306320160627\n",
            "Epoch :  45 / 100  loss :  4506.754997968674\n",
            "Epoch :  46 / 100  loss :  3295.9641712915895\n",
            "Epoch :  47 / 100  loss :  4246.606563001871\n",
            "Epoch :  48 / 100  loss :  4771.993777275085\n",
            "Epoch :  49 / 100  loss :  4606.60887150869\n",
            "Epoch :  50 / 100  loss :  3601.790501318622\n",
            "Epoch :  51 / 100  loss :  3973.9049597932026\n",
            "Epoch :  52 / 100  loss :  3611.0365656183567\n",
            "Epoch :  53 / 100  loss :  2199.829119682312\n",
            "Epoch :  54 / 100  loss :  3904.93978703022\n",
            "Epoch :  55 / 100  loss :  3273.0637398064137\n",
            "Epoch :  56 / 100  loss :  3301.5239689419104\n",
            "Epoch :  57 / 100  loss :  3325.6014351621225\n",
            "Epoch :  58 / 100  loss :  3810.977180232767\n",
            "Epoch :  59 / 100  loss :  2776.515985847712\n",
            "Epoch :  60 / 100  loss :  2821.8096079826355\n",
            "Epoch :  61 / 100  loss :  3692.320573568344\n",
            "Epoch :  62 / 100  loss :  2160.8246864099056\n",
            "Epoch :  63 / 100  loss :  2747.3381573855877\n",
            "Epoch :  64 / 100  loss :  3009.763688340783\n",
            "Epoch :  65 / 100  loss :  3596.504302293062\n",
            "Epoch :  66 / 100  loss :  3974.636982768774\n",
            "Epoch :  67 / 100  loss :  3124.7454798817635\n",
            "Epoch :  68 / 100  loss :  2850.828512282372\n",
            "Epoch :  69 / 100  loss :  2616.8674811024844\n",
            "Epoch :  70 / 100  loss :  2776.9326302679256\n",
            "Epoch :  71 / 100  loss :  3992.207460820675\n",
            "Epoch :  72 / 100  loss :  1948.2243834733963\n",
            "Epoch :  73 / 100  loss :  3918.0573292970657\n",
            "Epoch :  74 / 100  loss :  3006.050924271345\n",
            "Epoch :  75 / 100  loss :  3020.8879471719265\n",
            "Epoch :  76 / 100  loss :  1829.2727844119072\n",
            "Epoch :  77 / 100  loss :  2845.50111413002\n",
            "Epoch :  78 / 100  loss :  2278.90726736933\n",
            "Epoch :  79 / 100  loss :  2472.6952786445618\n",
            "Epoch :  80 / 100  loss :  2409.8908405618113\n",
            "Epoch :  81 / 100  loss :  3006.077276597023\n",
            "Epoch :  82 / 100  loss :  2341.656392097473\n",
            "Epoch :  83 / 100  loss :  3070.4754405617714\n",
            "Epoch :  84 / 100  loss :  3704.332493826747\n",
            "Epoch :  85 / 100  loss :  2572.6851724386215\n",
            "Epoch :  86 / 100  loss :  1824.3770952224731\n",
            "Epoch :  87 / 100  loss :  2944.7068403959274\n",
            "Epoch :  88 / 100  loss :  2218.0001445412636\n",
            "Epoch :  89 / 100  loss :  1624.1402758657932\n",
            "Epoch :  90 / 100  loss :  2324.4273116588593\n",
            "Epoch :  91 / 100  loss :  2882.384101331234\n",
            "Epoch :  92 / 100  loss :  2223.9055146123283\n",
            "Epoch :  93 / 100  loss :  2129.1777584552765\n",
            "Epoch :  94 / 100  loss :  2199.115665450692\n",
            "Epoch :  95 / 100  loss :  2500.813784480095\n",
            "Epoch :  96 / 100  loss :  2808.272971391678\n",
            "Epoch :  97 / 100  loss :  1890.3253116980195\n",
            "Epoch :  98 / 100  loss :  2905.2386773601174\n",
            "Epoch :  99 / 100  loss :  1768.6887273341417\n",
            "Accuracy :  0.9752\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9S6QJoVjhZQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c80086c6-ccde-4ed6-a19f-46d7114e121b"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(mnist.test.images[0].reshape(28,28))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0975ecc0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7+fkgQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0978037cc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}